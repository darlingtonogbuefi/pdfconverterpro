# .github/workflows/deploy-backend.yml

name: Deploy Backend & Worker to EC2 (SSM + OIDC)

on:
  push:
    branches:
      - main

permissions:
  id-token: write
  contents: read

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      # ============================
      # Checkout repository
      # ============================
      - name: Checkout repo
        uses: actions/checkout@v3

      # ============================
      # Configure AWS credentials via OIDC
      # ============================
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-east-1

      # ============================
      # Debug: verify AWS credentials
      # ============================
      - name: Test AWS OIDC credentials
        run: aws sts get-caller-identity

      # ============================
      # Setup Terraform (>=1.6.0)
      # ============================
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.7.0

      # ============================
      # Terraform Init (remote backend)
      # ============================
      - name: Terraform Init
        run: |
          cd infra_core_terraform
          terraform init -input=false

      # ============================
      # Get API Instance IDs from Terraform
      # ============================
      - name: Get API Instance IDs
        id: tf_api
        run: |
          cd infra_core_terraform     
          TF_API_RAW=$(terraform output -json api_instance_ids 2>/dev/null || true)
          TF_API_JSON=$(echo "$TF_API_RAW" | sed -n 's/^::debug::stdout: \(.*\)%0A$/\1/p')
          TF_API_JSON=${TF_API_JSON:-$TF_API_RAW}
          echo "$TF_API_JSON" | jq -e . >/dev/null || { echo "ERROR: Invalid JSON!"; exit 1; }
          API_IDS=$(echo "$TF_API_JSON" | jq -r '.[]')
          if [ -n "$API_IDS" ]; then
            echo "API_INSTANCE_IDS=$API_IDS" >> $GITHUB_ENV
          else
            echo "ERROR: No API instance IDs found!"; exit 1
          fi

      # ============================
      # Get Worker Instance IDs from Terraform
      # ============================
      - name: Get Worker Instance IDs
        id: tf_worker
        run: |
          cd infra_core_terraform
          TF_WORKER_RAW=$(terraform output -json worker_instance_ids 2>/dev/null || true)
          TF_WORKER_JSON=$(echo "$TF_WORKER_RAW" | sed -n 's/^::debug::stdout: \(.*\)%0A$/\1/p')
          TF_WORKER_JSON=${TF_WORKER_JSON:-$TF_WORKER_RAW}
          echo "$TF_WORKER_JSON" | jq -e . >/dev/null || { echo "ERROR: Invalid JSON!"; exit 1; }
          WORKER_IDS=$(echo "$TF_WORKER_JSON" | jq -r '.[]')
          if [ -n "$WORKER_IDS" ]; then
            echo "WORKER_IDS=$WORKER_IDS" >> $GITHUB_ENV
          else
            echo "ERROR: No Worker instance IDs found!"; exit 1
          fi

      # ============================
      # Deploy API via SSM (clone/update repo + run setup)
      # ============================
      - name: Deploy API via SSM with all secrets
        env:
          JOBS__FILES_S3_BUCKET: ${{ secrets.JOBS__FILES_S3_BUCKET }}
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_PORT: ${{ secrets.DB_PORT }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
          SQS_QUEUE_URL: ${{ secrets.SQS_QUEUE_URL }}
          VITE_BACKEND_URL: ${{ secrets.VITE_BACKEND_URL }}
          NUTRIENT_API_KEY: ${{ secrets.NUTRIENT_API_KEY }}
          NUTRIENT_BASE_URL: ${{ secrets.NUTRIENT_BASE_URL }}
          NUTRIENT_SESSION_URL: ${{ secrets.NUTRIENT_SESSION_URL }}
          NUTRIENT_SIGN_URL: ${{ secrets.NUTRIENT_SIGN_URL }}
          WORKER_HOST: ${{ secrets.WORKER_HOST }}
          API_HOST: ${{ secrets.API_HOST }}
          FRONTEND_S3_BUCKET: ${{ secrets.FRONTEND_S3_BUCKET }}
        run: |
          echo "DEBUG: Deploying API to $API_INSTANCE_IDS with bucket $JOBS__FILES_S3_BUCKET"

          COMMAND_ID=$(aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --instance-ids $API_INSTANCE_IDS \
            --comment "Deploy API from GitHub Actions" \
            --parameters "commands=[
              \"export HOME=/home/ubuntu\",
              \"export JOBS__FILES_S3_BUCKET=${JOBS__FILES_S3_BUCKET}\",
              \"export DB_HOST=${DB_HOST}\",
              \"export DB_PORT=${DB_PORT}\",
              \"export DB_USER=${DB_USER}\",
              \"export DB_PASSWORD=${DB_PASSWORD}\",
              \"export DB_NAME=${DB_NAME}\",
              \"export SQS_QUEUE_URL=${SQS_QUEUE_URL}\",
              \"export VITE_BACKEND_URL=${VITE_BACKEND_URL}\",
              \"export NUTRIENT_API_KEY=${NUTRIENT_API_KEY}\",
              \"export NUTRIENT_BASE_URL=${NUTRIENT_BASE_URL}\",
              \"export NUTRIENT_SESSION_URL=${NUTRIENT_SESSION_URL}\",
              \"export NUTRIENT_SIGN_URL=${NUTRIENT_SIGN_URL}\",
              \"export WORKER_HOST=${WORKER_HOST}\",
              \"export API_HOST=${API_HOST}\",
              \"export FRONTEND_S3_BUCKET=${FRONTEND_S3_BUCKET}\",
              \"if [ ! -d /home/ubuntu/pdfconverterpro ]; then git clone https://github.com/darlingtonogbuefi/pdfconverterpro.git /home/ubuntu/pdfconverterpro; fi\",
              \"cd /home/ubuntu/pdfconverterpro\",
              \"git config --global --add safe.directory /home/ubuntu/pdfconverterpro || git config --system --add safe.directory /home/ubuntu/pdfconverterpro\",
              \"git fetch origin\",
              \"git reset --hard origin/main\",
              \"if [ -f setup_api.sh ]; then chmod +x setup_api.sh; bash setup_api.sh; fi\"
            ]" \
            --timeout-seconds 3600 \
            --query "Command.CommandId" --output text)

          echo "SSM Command ID: $COMMAND_ID"

          while true; do
            STATUS=$(aws ssm list-command-invocations \
              --command-id "$COMMAND_ID" \
              --details \
              --query "CommandInvocations[0].Status" --output text)
            echo "Current status: $STATUS"
            if [[ "$STATUS" == "Success" || "$STATUS" == "Failed" || "$STATUS" == "Cancelled" ]]; then
              break
            fi
            sleep 5
          done

          aws ssm get-command-invocation \
            --command-id "$COMMAND_ID" \
            --instance-id "$API_INSTANCE_IDS"

      # ============================
      # Deploy Worker via SSM (clone/update repo + run setup)
      # ============================
      - name: Deploy Worker via SSM with all secrets
        env:
          JOBS__FILES_S3_BUCKET: ${{ secrets.JOBS__FILES_S3_BUCKET }}
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_PORT: ${{ secrets.DB_PORT }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
          SQS_QUEUE_URL: ${{ secrets.SQS_QUEUE_URL }}
          VITE_BACKEND_URL: ${{ secrets.VITE_BACKEND_URL }}
          NUTRIENT_API_KEY: ${{ secrets.NUTRIENT_API_KEY }}
          NUTRIENT_BASE_URL: ${{ secrets.NUTRIENT_BASE_URL }}
          NUTRIENT_SESSION_URL: ${{ secrets.NUTRIENT_SESSION_URL }}
          NUTRIENT_SIGN_URL: ${{ secrets.NUTRIENT_SIGN_URL }}
          WORKER_HOST: ${{ secrets.WORKER_HOST }}
          API_HOST: ${{ secrets.API_HOST }}
          FRONTEND_S3_BUCKET: ${{ secrets.FRONTEND_S3_BUCKET }}
        run: |
          echo "DEBUG: Deploying Worker to $WORKER_IDS with bucket $JOBS__FILES_S3_BUCKET"

          COMMAND_ID=$(aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --instance-ids $WORKER_IDS \
            --comment "Deploy Worker from GitHub Actions" \
            --parameters "commands=[
              \"export HOME=/home/ubuntu\",
              \"export JOBS__FILES_S3_BUCKET=${JOBS__FILES_S3_BUCKET}\",
              \"export DB_HOST=${DB_HOST}\",
              \"export DB_PORT=${DB_PORT}\",
              \"export DB_USER=${DB_USER}\",
              \"export DB_PASSWORD=${DB_PASSWORD}\",
              \"export DB_NAME=${DB_NAME}\",
              \"export SQS_QUEUE_URL=${SQS_QUEUE_URL}\",
              \"export VITE_BACKEND_URL=${VITE_BACKEND_URL}\",
              \"export NUTRIENT_API_KEY=${NUTRIENT_API_KEY}\",
              \"export NUTRIENT_BASE_URL=${NUTRIENT_BASE_URL}\",
              \"export NUTRIENT_SESSION_URL=${NUTRIENT_SESSION_URL}\",
              \"export NUTRIENT_SIGN_URL=${NUTRIENT_SIGN_URL}\",
              \"export WORKER_HOST=${WORKER_HOST}\",
              \"export API_HOST=${API_HOST}\",
              \"export FRONTEND_S3_BUCKET=${FRONTEND_S3_BUCKET}\",
              \"if [ ! -d /home/ubuntu/pdfconverterpro ]; then git clone https://github.com/darlingtonogbuefi/pdfconverterpro.git /home/ubuntu/pdfconverterpro; fi\",
              \"cd /home/ubuntu/pdfconverterpro\",
              \"git config --global --add safe.directory /home/ubuntu/pdfconverterpro || git config --system --add safe.directory /home/ubuntu/pdfconverterpro\",
              \"git fetch origin\",
              \"git reset --hard origin/main\",
              \"if [ -f setup_worker.sh ]; then chmod +x setup_worker.sh; bash setup_worker.sh; fi\"
            ]" \
            --timeout-seconds 3600 \
            --query "Command.CommandId" --output text)

          echo "SSM Command ID: $COMMAND_ID"

          while true; do
            STATUS=$(aws ssm list-command-invocations \
              --command-id "$COMMAND_ID" \
              --details \
              --query "CommandInvocations[0].Status" --output text)
            echo "Current status: $STATUS"
            if [[ "$STATUS" == "Success" || "$STATUS" == "Failed" || "$STATUS" == "Cancelled" ]]; then
              break
            fi
            sleep 5
          done

          aws ssm get-command-invocation \
            --command-id "$COMMAND_ID" \
            --instance-id "$WORKER_IDS"
